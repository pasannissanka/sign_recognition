{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T06:36:19.727109029Z",
     "start_time": "2023-05-03T06:36:19.522756188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  3 12:18:49 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060         On | 00000000:07:00.0 Off |                  N/A |\n",
      "| 77%   43C    P8               23W / 170W|   1338MiB / 12288MiB |      7%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      5384      G   /usr/lib/xorg/Xorg                          614MiB |\n",
      "|    0   N/A  N/A      5504      G   /usr/bin/gnome-shell                        179MiB |\n",
      "|    0   N/A  N/A      6368      G   ./jetbrains-toolbox                           9MiB |\n",
      "|    0   N/A  N/A     11959      G   ...6114711,17027406532007204771,131072      481MiB |\n",
      "|    0   N/A  N/A     52203      G   ...ures=SpareRendererForSitePerProcess       49MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pasannissanka/Projects/SignRecognition/code/model training/yolov5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: cannot change to '/home/pasannissanka/Projects/SignRecognition/code/model': No such file or directory\n",
      "YOLOv5 🚀 2023-5-3 Python-3.10.6 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12036MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (16 CPUs, 31.2 GB RAM, 594.0/883.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "TensorFlow installation not found - running with reduced feature set.\n",
       "\n",
       "NOTE: Using experimental fast data loading logic. To disable, pass\n",
       "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
       "    https://github.com/tensorflow/tensorboard/issues/4784\n",
       "\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs/train/exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.0.5-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m953.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting idna==2.10\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: matplotlib in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (3.7.1)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (9.5.0)\n",
      "Collecting requests-toolbelt\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wget\n",
      "  Using cached wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cycler==0.10.0\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (1.24.2)\n",
      "Requirement already satisfied: six in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (1.26.15)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting chardet==4.0.0\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: certifi==2022.12.7 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: requests in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (2.29.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (4.7.0.72)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from roboflow) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from matplotlib->roboflow) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from matplotlib->roboflow) (23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from matplotlib->roboflow) (4.39.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pasannissanka/Projects/SignRecognition/code/venv/lib/python3.10/site-packages (from requests->roboflow) (3.1.0)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=05abdc9fe1ac7fa76a8f5f1000f1c0128a0f1594c660dfcb762e429491d035fa\n",
      "  Stored in directory: /home/pasannissanka/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, chardet, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "Successfully installed chardet-4.0.0 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.0.5 wget-3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in traffic-signs-merged-2-2 to yolov5pytorch: 100% [452833985 / 452833985] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to traffic-signs-merged-2-2 in yolov5pytorch:: 100%|██████████| 18932/18932 [00:01<00:00, 11503.06it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"mFmQZLll44oUekOTuMai\")\n",
    "project = rf.workspace(\"project-ypnwz\").project(\"traffic-signs-merged-2\")\n",
    "dataset = project.version(2).download(\"yolov5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=traffic-signs-merged-2-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /home/pasannissanka/Projects/SignRecognition/code/model training/requirements.txt not found, check failed.\n",
      "fatal: cannot change to '/home/pasannissanka/Projects/SignRecognition/code/model': No such file or directory\n",
      "YOLOv5 🚀 2023-5-3 Python-3.10.6 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12036MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=35\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    107880  models.yolo.Detect                      [35, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7114024 parameters, 7114024 gradients, 16.2 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/pasannissanka/Projects/SignRecognition/code/model training\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/pasannissanka/Projects/SignRecognition/code/model training/y\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.66 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp3/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/9      3.51G    0.06294    0.02069    0.07987         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.745     0.0839     0.0778     0.0429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/9      4.32G    0.04425     0.0124    0.06573         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.734      0.209      0.163      0.097\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/9      4.32G    0.04242    0.01032    0.04929         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.839      0.265       0.31      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/9      4.32G    0.03869   0.009545    0.03567         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.895      0.327      0.387      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/9      4.32G    0.03642   0.009051    0.02894         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.902       0.39      0.431      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        5/9      4.32G    0.03363   0.008663    0.02427         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.877      0.428      0.521      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        6/9      4.32G    0.03129   0.008336    0.02073         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.797      0.549      0.608      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        7/9      4.32G    0.02932   0.007926    0.01816         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.908      0.553      0.679      0.459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        8/9      4.32G    0.02751   0.007691    0.01517         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.808      0.644       0.74        0.5\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        9/9      4.32G    0.02577   0.007506    0.01292         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897       0.81      0.676      0.767      0.537\n",
      "\n",
      "10 epochs completed in 0.227 hours.\n",
      "Optimizer stripped from runs/train/exp3/weights/last.pt, 14.6MB\n",
      "Optimizer stripped from runs/train/exp3/weights/best.pt, 14.6MB\n",
      "\n",
      "Validating runs/train/exp3/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7104520 parameters, 0 gradients, 16.0 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897       0.81      0.676      0.767      0.537\n",
      "            bend_ahead        667         23      0.958      0.998      0.993      0.798\n",
      "         bus_only_lane        667         42      0.912      0.988      0.993      0.728\n",
      "              bus_stop        667         15      0.624        0.8      0.761      0.601\n",
      "       chevron_markers        667         88       0.76      0.875      0.885      0.518\n",
      "children_crossing_ahead        667         13      0.866      0.769      0.848       0.61\n",
      "directional_express_way        667         46      0.726      0.891      0.849      0.618\n",
      "    directional_normal        667         59      0.774      0.949       0.96      0.704\n",
      "            expressway        667         13       0.75          1      0.995      0.725\n",
      "              give_way        667          9      0.828          1      0.995      0.553\n",
      "          height_limit        667          2      0.742          1      0.995      0.622\n",
      "              hospital        667          4          1          0       0.61      0.216\n",
      "        level_crossing        667         14      0.864      0.786      0.786      0.502\n",
      "level_crossing_gates_ahead        667          4          1          0      0.257      0.221\n",
      "    light_signal_ahead        667          9      0.659      0.889      0.896      0.575\n",
      "           merge_ahead        667         53      0.922      0.943      0.951       0.72\n",
      "              no_entry        667          9      0.795      0.889      0.797      0.598\n",
      "            no_horning        667          5      0.189        0.6      0.303      0.264\n",
      "            no_parking        667         22      0.895      0.955      0.958      0.762\n",
      "               no_turn        667         59      0.656      0.966      0.967      0.696\n",
      "             no_u_turn        667         20      0.572        0.4      0.637      0.426\n",
      "               one_way        667          2          1          0     0.0559     0.0473\n",
      "               parking        667          7      0.617      0.243      0.641      0.411\n",
      "                  pass        667         42      0.978      0.929      0.966      0.717\n",
      "   pedestrian_crossing        667        119      0.835      0.975      0.978      0.662\n",
      "pedestrian_crossing_ahead        667         59      0.853      0.898      0.915      0.654\n",
      "           road_closed        667          5          1          0      0.478      0.358\n",
      "    road_narrows_ahead        667          7          1          0      0.422      0.281\n",
      "      road_works_ahead        667          6       0.39        0.5      0.583      0.389\n",
      "            roundabout        667          9          1          0       0.27      0.185\n",
      "      roundabout_ahead        667          9      0.789      0.831      0.886      0.578\n",
      "             side_road        667         20       0.85       0.95      0.919      0.673\n",
      "           speed_limit        667         83      0.931      0.976      0.984      0.711\n",
      "                  stop        667         14      0.791          1       0.99      0.712\n",
      "                  turn        667          6          1          0      0.564      0.432\n",
      "Results saved to \u001b[1mruns/train/exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 10 --data traffic-signs-merged-2-2/data.yaml --weights yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=traffic-signs-merged-2-2/data.yaml, weights=['runs/train/exp2/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /home/pasannissanka/Projects/SignRecognition/code/model training/requirements.txt not found, check failed.\n",
      "fatal: cannot change to '/home/pasannissanka/Projects/SignRecognition/code/model': No such file or directory\n",
      "YOLOv5 🚀 2023-5-3 Python-3.10.6 torch-2.0.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12036MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20990328 parameters, 0 gradients, 48.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/pasannissanka/Projects/SignRecognition/code/model training/y\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        667        897      0.968      0.914      0.949      0.727\n",
      "            bend_ahead        667         23      0.985          1      0.995      0.828\n",
      "         bus_only_lane        667         42      0.998          1      0.995      0.805\n",
      "              bus_stop        667         15      0.918        0.8       0.79       0.63\n",
      "       chevron_markers        667         88      0.986      0.777      0.943      0.604\n",
      "children_crossing_ahead        667         13          1      0.933      0.995      0.794\n",
      "directional_express_way        667         46      0.898       0.87      0.911      0.673\n",
      "    directional_normal        667         59      0.964      0.905      0.982      0.783\n",
      "            expressway        667         13      0.995          1      0.995      0.719\n",
      "              give_way        667          9       0.99          1      0.995      0.762\n",
      "          height_limit        667          2      0.941          1      0.995      0.572\n",
      "              hospital        667          4      0.942          1      0.995      0.808\n",
      "        level_crossing        667         14      0.983      0.857      0.856      0.685\n",
      "level_crossing_gates_ahead        667          4      0.948       0.75      0.752      0.572\n",
      "    light_signal_ahead        667          9          1      0.952      0.995      0.665\n",
      "           merge_ahead        667         53       0.98      0.917      0.963      0.787\n",
      "              no_entry        667          9      0.943          1      0.995      0.765\n",
      "            no_horning        667          5      0.897          1      0.995      0.741\n",
      "            no_parking        667         22          1      0.968      0.995      0.794\n",
      "               no_turn        667         59      0.997      0.932      0.992      0.813\n",
      "             no_u_turn        667         20          1      0.836       0.99        0.7\n",
      "               one_way        667          2      0.868        0.5      0.745      0.522\n",
      "               parking        667          7      0.934          1      0.995      0.677\n",
      "                  pass        667         42          1      0.917      0.995      0.804\n",
      "   pedestrian_crossing        667        119      0.977      0.966      0.991      0.749\n",
      "pedestrian_crossing_ahead        667         59          1      0.949      0.971      0.781\n",
      "           road_closed        667          5      0.926        0.6      0.636      0.554\n",
      "    road_narrows_ahead        667          7      0.966          1      0.995      0.821\n",
      "      road_works_ahead        667          6      0.984          1      0.995      0.863\n",
      "            roundabout        667          9      0.978      0.889      0.905      0.666\n",
      "      roundabout_ahead        667          9          1       0.81      0.928      0.638\n",
      "             side_road        667         20          1      0.958      0.995      0.831\n",
      "           speed_limit        667         83      0.976      0.979       0.99      0.777\n",
      "                  stop        667         14      0.987          1      0.995       0.82\n",
      "                  turn        667          6      0.965          1      0.995      0.711\n",
      "Speed: 0.2ms pre-process, 10.2ms inference, 0.6ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --weights runs/train/exp2/weights/best.pt --data traffic-signs-merged-2-2/data.yaml --img 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
